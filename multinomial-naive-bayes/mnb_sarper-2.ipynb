{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lGn8lqEO6rM1"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "#nltk.download () # Download only required or all -> press d, type all, type quit after\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score, confusion_matrix, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wfhBZiBj9_Ac"
   },
   "outputs": [],
   "source": [
    "train_path = \"content/training.csv\"\n",
    "val_path = \"content/validation.csv\"\n",
    "test_path = \"content/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization method to tokenize our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FreHSkdM-eE8"
   },
   "outputs": [],
   "source": [
    "def tokenize(column):\n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    return [w for w in tokens if w.isalpha()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IourfoJ4AG_A"
   },
   "outputs": [],
   "source": [
    "train_df['tokenized'] = train_df.apply(lambda x: tokenize(x['text']), axis=1)\n",
    "val_df['tokenized'] = val_df.apply(lambda x: tokenize(x['text']), axis=1)\n",
    "test_df['tokenized'] = test_df.apply(lambda x: tokenize(x['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouC8E6rhFDVx",
    "outputId": "9a1337af-aeec-4821-fcd2-71ad455645ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                             [i, didnt, feel, humiliated]\n",
      "1        [i, can, go, from, feeling, so, hopeless, to, ...\n",
      "2        [im, grabbing, a, minute, to, post, i, feel, g...\n",
      "3        [i, am, ever, feeling, nostalgic, about, the, ...\n",
      "4                                [i, am, feeling, grouchy]\n",
      "                               ...                        \n",
      "15995    [i, just, had, a, very, brief, time, in, the, ...\n",
      "15996    [i, am, now, turning, and, i, feel, pathetic, ...\n",
      "15997                [i, feel, strong, and, good, overall]\n",
      "15998    [i, feel, like, this, wa, such, a, rude, comme...\n",
      "15999    [i, know, a, lot, but, i, feel, so, stupid, be...\n",
      "Name: lemmatized, Length: 16000, dtype: object\n",
      "0       [im, feeling, quite, sad, and, sorry, for, mys...\n",
      "1       [i, feel, like, i, am, still, looking, at, a, ...\n",
      "2                   [i, feel, like, a, faithful, servant]\n",
      "3               [i, am, just, feeling, cranky, and, blue]\n",
      "4       [i, can, have, for, a, treat, or, if, i, am, f...\n",
      "                              ...                        \n",
      "1995    [im, having, ssa, examination, tomorrow, in, t...\n",
      "1996    [i, constantly, worry, about, their, fight, ag...\n",
      "1997    [i, feel, it, important, to, share, this, info...\n",
      "1998    [i, truly, feel, that, if, you, are, passionat...\n",
      "1999    [i, feel, like, i, just, wan, na, buy, any, cu...\n",
      "Name: lemmatized, Length: 2000, dtype: object\n",
      "0       [im, feeling, rather, rotten, so, im, not, ver...\n",
      "1       [im, updating, my, blog, because, i, feel, shi...\n",
      "2       [i, never, make, her, separate, from, me, beca...\n",
      "3       [i, left, with, my, bouquet, of, red, and, yel...\n",
      "4       [i, wa, feeling, a, little, vain, when, i, did...\n",
      "                              ...                        \n",
      "1995    [i, just, keep, feeling, like, someone, is, be...\n",
      "1996    [im, feeling, a, little, cranky, negative, aft...\n",
      "1997    [i, feel, that, i, am, useful, to, my, people,...\n",
      "1998    [im, feeling, more, comfortable, with, derby, ...\n",
      "1999    [i, feel, all, weird, when, i, have, to, meet,...\n",
      "Name: lemmatized, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "train_df['lemmatized'] = train_df['tokenized'].apply(\n",
    "                    lambda lst:[lmtzr.lemmatize(word) for word in lst])\n",
    "val_df['lemmatized'] = val_df['tokenized'].apply(\n",
    "                   lambda lst:[lmtzr.lemmatize(word) for word in lst])\n",
    "test_df['lemmatized'] = test_df['tokenized'].apply(\n",
    "                   lambda lst:[lmtzr.lemmatize(word) for word in lst])\n",
    "\n",
    "print(train_df['lemmatized'])\n",
    "print(val_df['lemmatized'])\n",
    "print(test_df['lemmatized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAblLA67bLeP"
   },
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "rFFieocabM64",
    "outputId": "3923126b-175c-4195-97b0-076a8ea3ce24",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      i didnt feel humili\n",
       "1        i can go from feel so hopeless to so damn hope...\n",
       "2              im grab a minut to post i feel greedi wrong\n",
       "3        i am ever feel nostalg about the fireplac i wi...\n",
       "4                                        i am feel grouchi\n",
       "                               ...                        \n",
       "15995    i just had a veri brief time in the beanbag an...\n",
       "15996    i am now turn and i feel pathet that i am stil...\n",
       "15997                        i feel strong and good overal\n",
       "15998    i feel like this wa such a rude comment and im...\n",
       "15999    i know a lot but i feel so stupid becaus i can...\n",
       "Name: lemmatized, Length: 16000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       im feel quit sad and sorri for myself but ill ...\n",
       "1       i feel like i am still look at a blank canva b...\n",
       "2                             i feel like a faith servant\n",
       "3                          i am just feel cranki and blue\n",
       "4           i can have for a treat or if i am feel festiv\n",
       "                              ...                        \n",
       "1995    im have ssa examin tomorrow in the morn im qui...\n",
       "1996    i constant worri about their fight against nat...\n",
       "1997    i feel it import to share this info for those ...\n",
       "1998    i truli feel that if you are passion enough ab...\n",
       "1999    i feel like i just wan na buy ani cute make up...\n",
       "Name: lemmatized, Length: 2000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       im feel rather rotten so im not veri ambiti ri...\n",
       "1                   im updat my blog becaus i feel shitti\n",
       "2       i never make her separ from me becaus i don t ...\n",
       "3       i left with my bouquet of red and yellow tulip...\n",
       "4              i wa feel a littl vain when i did this one\n",
       "                              ...                        \n",
       "1995    i just keep feel like someon is be unkind to m...\n",
       "1996    im feel a littl cranki negat after this doctor...\n",
       "1997    i feel that i am use to my peopl and that give...\n",
       "1998    im feel more comfort with derbi i feel a thoug...\n",
       "1999    i feel all weird when i have to meet w peopl i...\n",
       "Name: lemmatized, Length: 2000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "train_df['lemmatized'] = train_df.lemmatized.map(lambda l: [stemmer.stem(word) for word in l])\n",
    "train_df.lemmatized = train_df.lemmatized.str.join(sep=' ')\n",
    "\n",
    "val_df['lemmatized'] = val_df.lemmatized.map(lambda l: [stemmer.stem(word) for word in l])\n",
    "val_df.lemmatized = val_df.lemmatized.str.join(sep=' ')\n",
    "\n",
    "test_df['lemmatized'] = test_df.lemmatized.map(lambda l: [stemmer.stem(word) for word in l])\n",
    "test_df.lemmatized = test_df.lemmatized.str.join(sep=' ')\n",
    "\n",
    "display(train_df[\"lemmatized\"])\n",
    "display(val_df[\"lemmatized\"])\n",
    "display(test_df[\"lemmatized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvcBsQj7aq8Z"
   },
   "source": [
    "Preprocessing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "gmNXwBhwYMtZ",
    "outputId": "388d12c9-8bda-4901-b612-52336e3e9e82",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16000x10082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 136700 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<2000x10082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16253 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<2000x10082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16432 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "train_ppd_df = cv.fit_transform(train_df[\"lemmatized\"])\n",
    "val_ppd_df = cv.transform(val_df[\"lemmatized\"])\n",
    "test_ppd_df = cv.transform(test_df[\"lemmatized\"])\n",
    "\n",
    "\n",
    "display(train_ppd_df)\n",
    "display(val_ppd_df)\n",
    "display(test_ppd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uPJ4niqqc9tI"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array(train_df['label'])\n",
    "val_labels = np.array(val_df['label'])\n",
    "test_labels = np.array(test_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvcBsQj7aq8Z"
   },
   "source": [
    "Now training our model with Multinomial Naive Bayes and testing the accuracy with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk3LcMqTcbk8",
    "outputId": "de61a559-6553-4744-c752-8ab4bcad3ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  77.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[528,  38,   2,   8,   5,   0],\n",
       "       [ 22, 653,   8,   7,   5,   0],\n",
       "       [ 27,  76,  51,   4,   1,   0],\n",
       "       [ 58,  30,   0, 180,   7,   0],\n",
       "       [ 49,  29,   0,   9, 137,   0],\n",
       "       [ 16,  33,   0,   1,  14,   2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_ppd_df,train_labels)\n",
    "predictions_NB = mnb.predict(test_ppd_df)\n",
    "\n",
    "print(\"Accuracy Score -> \",accuracy_score(predictions_NB, test_labels)*100)\n",
    "confusion_matrix(y_true=test_labels, y_pred=predictions_NB)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
